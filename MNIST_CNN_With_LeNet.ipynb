{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zSzFxNadQuD"
   },
   "source": [
    "#MNIST LeNet-5 CNN With Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QO_XjeB3dwlR"
   },
   "source": [
    "## Load Libraries and Mount Google Drive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "bYoUVcjzBR5W",
    "outputId": "fd399408-0f3e-4ab3-a4ff-240e79d0ef5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ce99XItid74v"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpE5tCXeBUvG"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Tugas 2 Deep Learning/Dataset/train.csv')\n",
    "X_train = df_train.iloc[:, 1:]\n",
    "Y_train = df_train.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "XJUaLsi8BWKo",
    "outputId": "bf8ebcb0-8cd6-4905-aff3-b0d28cc997ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0       0       0       0       0  ...         0         0         0         0\n",
       "1       0       0       0       0  ...         0         0         0         0\n",
       "2       0       0       0       0  ...         0         0         0         0\n",
       "3       0       0       0       0  ...         0         0         0         0\n",
       "4       0       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "L9KchRxoBZhq",
    "outputId": "5c43ed2a-614d-4ff3-dd07-9bf6ecece8dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    4\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVqHba4vBZ9A"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aYThF87FBfvs"
   },
   "outputs": [],
   "source": [
    "# Normalize inputs\n",
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m89fEeeAeBg8"
   },
   "source": [
    "##Plot Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6o0IjL0YBhKN"
   },
   "outputs": [],
   "source": [
    "def plot_digits(X, Y):\n",
    "    for i in range(20):\n",
    "        plt.subplot(5, 4, i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title('Digit:{}'.format(Y[i]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "NmcK9xhKBikD",
    "outputId": "0c70658c-9e90-482c-913e-6ddd08bd5c39"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAELCAYAAADuufyvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2deXwUVbr3vycQwhKSCAkoIGEQmQiZ\nAQEVFSQZXMgFHBlGRl8U5Y4IXF9nZOZV5OMWQUe5juAyCooLLoz7wuSqKHIjgoogaFAWGWRYHAIY\nMBACBLr6ef/opO3snXTXkvTz/XyeT1J1Tp3zVP3qPHX6VNUpIyIoiqIo7hPntgOKoihKAA3IiqIo\nHkEDsqIoikfQgKwoiuIRNCAriqJ4BA3IiqIoHiHigGyMmW+MuSPaeZXGo5p4D9XEW3hWDxGp04Dt\nwFGgBCgGPgWmAHH1bVtPuVnA9/XkyQTeB4oCrja+vuZkbmpSnm8asAc4BDwDJLh9TNw2bSfeMrfb\nSEj+ZYAALcPJH24PebSItAfSgfuB6cDTYW4bCSeAV4HfO1BXU8MVTYwxlwC3AsPL6+4J3G13vU0E\nbSfewi09ADDGjAfiG7RRmFeaC6usOxvwE7gyLwTuCUm7BSgEdgPXEbg69CpPWwjcA7QjcPXyA4fL\nrUsdPvRCr/ye0AT4O/CXkOXhwB63j4nbpu3EW+a2HkAysAUYjA095EqIyGrge2Bo6HpjzAjgT8CF\n5SdHVi3blwI5wG4RSSy33caYIcaY4sb4FOs4qElfoCBkuQDobIzpGLWdaSZoO/EWDuvxF2AegaG9\nsInkpt5uoEOVdeOAZ0Vkg4gcAXIbUqCIrBSRlAh8inWc0CQROBiyXPF/+wb6GitoO/EWtuthjBkE\nnA882lDnIgnIXYEDVdZ1AXaFLO9CcRInNDkMJIUsV/xfEmG5zRVtJ97CVj2MMXHA48AfRcTX0O0b\nFZCNMWcR2LGVVZIKgW4hy6fWUYxOMxdFHNRkA9AvZLkfsFdE9ofjZyyh7cRbOKRHEjAIeMUYswdY\nU77+e2PM0No3C9CggGyMSTLGjAJeBl4Uka+rZHkVmGiMOcMY0xao69m9vUBHY0xyHfUZY0xroFX5\ncmtjTEJDfG7uOK0J8Dzwe2NMH2NMCnA7gZseSjnaTryFw3ocJNDj7l9u/1G+fiDweX2+hhuQ84wx\nJQS68rcBc4CJVTOJyHvAI0A+sBVYVZ5UVkPezcBLwDZjTLExposxZqgx5nBItnQCdzU3lC8fBb4N\n0+fmjiuaiMgS4L/Ly9sJ7ADuiuaONWG0nXgLx/WQAHsqDPihfNO9InK8PodN+SMatmCMOQP4hsCL\nAw0eT1Gij2riPVQTb+GmHlGfy8IYM8YYk2CMOQmYDeTpSeYuqon3UE28hVf0sGNyocnAPuA7wAKm\n2lCH0jBUE++hmngLT+hh65CFoiiKEj46/aaiKIpH0ICsKIriEVpGWoAxxrYxDxExdpXdnFFNvIWd\negBFIpJmY/nNEq+2Ee0hK0rTZofbDijRw/WA/OGHHyIiTJgwwW1XYoYOHTrQvXt3Zs+ezUcffcS4\nceMYMWIExmjn101atGjBAw88QIsWLdx2RXGLKMw7KpHY8ePHxbIsufrqq6ulRepbrFpdx3vcuHFy\n/Phx8fv9Qfv222/lyJEjMm/ePOnRo0ederm9b03Rwm0Lbdq0Eb/fL61bt25IG/rC7f1rilbTsdy6\ndavk5eXVq9Ho0aNtayOOnWw12W233SaWZclLL70kbdu21cZv48kGSEpKSqVAXJMVFhZKcnKyBmQH\n9NCA7C1NunXrJkePHq3zeHft2lVWr15tW0B2bcjisssu4/bbb+frr7/m+uuv58iRI265EjMMHjy4\n3jydO3fmyiuvdMAbpTYmTqw23YLiAN9//z0nTpyoN9+gQYNs88HxgHz22WdTUFDAG2+8QatWrejf\nvz8lJTqVrt28/vrrvPvuuwB88cUXPPbYYzz22GPExcXRvn170tPTWb16NQCPP/44r732mpvuxjS/\n/vWv3XYhZnnwwQdJS6v9oZWysjIOHjxYa3qkRPzYW0O4+uqree655xARDh48yIcffuhk9TGLMYa4\nuMC1d/z48ezbt49ly5YF00tLSyktLWXJkiUMGjSIuLg4MjIyGDVqFP/zP//jltuK4jjr1q2rM72o\nqIhvvvnGtvod7SHffPPNwf8XL17MuHHjnKw+ZvnlL3/JZZddBsDKlSsrBeNQcnNz+d3vfgdA3759\nGT16tGM+KmBZltsuxDxlZdVm3HQUxwJySkoKffv2BaCkpIR//OMfTlUd8/zsZz8L/l/fGNmnn35q\ntztKLRw/Xu90uYrNHDp0yNX6HQnIqamp/O///i/GGFatWkXnzp156623nKg65klKSmL+/PnB5fj4\n+DrzFxYWBv+fNGkSJ510km2+KZVp06aN2y7EPKtWrWL37t1kZGTUmmfBggVcdNFFttTvSED+29/+\nRr9+/fjkk0/Izs52/WdBLNGyZUs6derkthuK0mT48ccfeeihh2pNf+edd2yr2/aAnJqaymmnnQbA\n7NmzNRg7THFxMYsWLXLbDUVpUtT1JEVxcTHTpk2jbdu2Ua/X1oDcqVMnXn75ZQYMGMCxY8f0jr0L\n+P1+li5dGlx+7bXXSExMrDV/SkpK8P/58+dTXFxsq3+K4jXefvttevXqRcuWgYfQunTpwogRI8jN\nzWXNmjWsXbuWESNGMGPGjOhXbudbSJMnTxbLssSyLMnPz2/wm3xuv83TVK3qcUxOTpZ169YF38Zb\nvXq1ZGdnVzveaWlp8txzz4nf75fS0lJJT09XTWzQozareFNvyZIl+qaei5oMGTJE/H6/3H333TJt\n2jQpLS2VEydOyLJly2TkyJEyePBg8fv9kpOTE/W4ZduOJScnB4PxZZdd1uBgrI0/+pqMGzeu2qvS\ne/fulZKSkmrrx40bp5rYrEdVe//990VENCB7SJPazK6AbNuQRejbRklJSXZVozSAV199tdq6tLQ0\n2rVrV2ndFVdcYeuNC6V2yoOFEqPYFpArnne1LIvTTz/drmqUBrJkyZI600tLS3n11VcpLS11yCNF\naXp89dVX9OjRI/oF29n137Jli1xzzTWN/lng9s+apmp1HdPWrVvLqFGj5JFHHgkOT4iIPPLII9Kx\nY8c6Z3pTTaKvR6gNGzZM/H6/XHDBBTpk4RFNarMPPvhAnn322ai3kYi/Ou3VT6HEMqqJt7D5E05r\nRcS+6ceaKZFqUlBQwN/+9jcWLFhQLS2SNqIBuRmimngLDcjew6ttxPVPOCmKoigBojH9ZhH2fGgx\n3YYyYwXVxFvYpQeoJo3Fk20k4iELRVEUJTrokIWiKIpH0ICsKIriETQgK4qieAQNyIqiKB5BA7Ki\nKIpH0ICsKIriETQgK4qieAQNyIqiKB5BA7KiKIpH0ICsKIriETQgK4qieAQNyIqiKB5BA7KiKIpH\niDggG2PmG2PuiHZepfGoJt5DNfEWntUjjG9PbQeOAiVAMfApMAWIi/CbVlnA92HkmwbsAQ4BzwAJ\nbn+Py21TTbxnbmoCzAcOh1gZUOL2MYlhPa4AvgUOAvuA54CkcMoPt4c8WkTaE5h8+X5gOvB0mNs2\nGmPMJcCtwPDyunsCd9tdbxNBNfEermgiIlNEJLHCgJeA1+yutwngih7AJ8D5IpJMoH20BO4Ja8sw\nrzQXVll3NuAHMoGFwD0habcAhcBu4DoCX2LtVZ62sNyxdgSuXn5+uqp3qaHuvwN/CVkeDuxx++rr\ntqkm3jM3NalSZzsCvcJhbh8T1UMAEoHngXfD8btRY8gishr4Hhgaut4YMwL4E3Ah0ItA976m7UuB\nHGC3/HRl322MGWKMKQ7J2hcoCFkuADobYzo2xu/mjGriPRzUJJSxwA/Ax9HZi+aDk3qUrztI4OI4\nFngoHB8juam3G+hQZd044FkR2SAiR4DchhQoIitFJCVkVSKBcZgKKv5v30BfYwXVxHs4oUko1wDP\nS3n3TKmGI3qUr0sGugEPEOix10skAbkrcKDKui7ArpDlXUTGYSApZLni/5IIy22uqCbewwlNADDG\ndCfQu3s+GuU1UxzTA0BE/g0sAV4OJ3+jArIx5iwCO7aySlIhgStCBafWUUw4V/ANQL+Q5X7AXhHZ\nH46fsYRq4j0c1KSCq4FPRGRbA7aJGVzQo4KWwGnhZGxQQDbGJBljRhGI9i+KyNdVsrwKTDTGnGGM\naQvU9ezeXqCjMSa5jjzPA783xvQxxqQAtxMYYFfKUU28hwuaVDAB1aIaTuthjBlf/msFY0w6cC+w\nLBxfww3IecaYEgJd+duAOcDEqplE5D3gESAf2AqsKk8qqyHvZgKP52wzxhQbY7oYY4YaYw6H5FkC\n/Hd5eTuBHcBdYfrc3FFNvIcrmgAYY84l0MvTx91+wi09+gCfGmNKCTwC9y0wKRyHjZ1j/8aYM4Bv\nCLw44LOtIiVsVBPvoZp4Czf1iPpcFsaYMcaYBGPMScBsIE9PMndRTbyHauItvKKHHZMLTSbwuuB3\ngAVMtaEOpWGoJt5DNfEWntDD1iELRVEUJXx0+k1FURSPoAFZURTFI7SMtABjjG1jHiJi7Cq7OaOa\neAs79QCKRCTNxvKbJV5tI9pDVpSmzQ63HVCih60B2RjDKaecwqxZs3jqqaeCU8w988wzdO/enbg4\nvR64SYsWLVi9ejV+v5/ly5eTmZnptkuKEtNE/JRFXV3/yZMnM2/evFq3/fOf/8zcuXNrTdefx40j\nnJ9j8fHxLFy4kKSkJIqLixk3bhzHjx/n8ssvZ8mSJbVup5o0HJuHLNaKyCAby2+WeHXIwraA3K5d\nO0pK6p8ArK5esjb+xhHOyXbfffcxffr04PFftmwZ2dnZlJaW0r597TNpqiYNRwOy96hLk7S0NG68\n8UaGDBlCVlYWPp+Pd955h82bN/Ptt98C8OKLL+Lz1fzeSERtJAoz80tNlp6eLn6/v16bNGmStGjR\nosYyIvUtVq02TSpszJgxcuzYMSkoKAiue+GFF6SoqEj8fn+d27q9b03RatNg/vz5MnDgQBk4cKCk\npaVJRkZGcHngwIEybdo0Wb58uXTv3r0uTb5we/+aotV0LLt06SLXX399MDYdO3ZMtm3bJjt27KgW\nt9atWyc33XSTtGzZMqptxJYe8uzZs7n55psB2LNnD5MnTyYvLw+Aiy++mMcee4zTTvtpNrotW7Yw\na9YsFi1aVKkc0d5Yo6jr6j99+nTuu+8+nnnmGSZPnoxlWcG0Dh068M0333Deeeexffv2GrdXTRpO\nTXrcdttt/PDDD7VuM2TIEK666ipEhBYtWtRVvPaQG0FNmowfP57U1FQefvjhSutHjBhBamoqL774\nYnBdYmIi33zzDYcOHWLgwIGcOHEimBZRG4n2lSY+Pl42bdoUvJKsWLGi2hVkypQp1a46mzdvllNP\nPVV7YzZd/Svs66+/Fr/fL6eddlq1tB49eojf75cePXpoD9lmPdasWSPXX399rcf5vffeE8uy5Ouv\nv67zFwvaQ46aJuHagAEDpLi4WPx+v2RnZ0e1jUT9MYc//vGP/PznPwfg+PHj3H///dXyzJ8/n3PP\nPZc1a9YE1/Xu3ZsPP/yQli0jfjRaqYO+ffvy1FNP1doDVpwjIyOjxvXt2rWje/fuGGNqbD+K8yQk\nJDBjxgy2bt3KF198wfr16znppJPIz8+Paj1Rj34PPPBAxRWINWvW8M4779SYb/fu3YwZM4bvv/8+\nuO7000/HGP1FbDfffvttpaGKCnJzcwE4evSowx7FFhkZGWRkZLBgwYJa03/+85/z5ptv8tZbbzns\nXWzTunVrpkyZElwuLCzk7LPPZvTo0XTv3p3333+fKVOm8OGHH9rjQLS7/iISHIb4/e9/X2/3f/v2\n7ZWGLmbOnKk/j236Oda5c2f57rvvpF27djWmf/rppyKBAnTIwmY9UlNTJTU1tcZjbFmW+Hy+Ooc0\nQkyHLKKkSYX16NGjkm3atElWrFgh/fr1C2tIIxK/XH8zY+HChW67EFNs2LCB0tLSauvbtm1LWlpa\nxcmq2ExRURFFRUXV1l9wwQUYYzDG8PHHH7vgmbJ9+/ZK1q9fP15//XWWLFnCm2++SXx8vG11ux6Q\nExMTKy1v2rTJJU+aPwkJCXTp0qXGtOTkZFJSavuyvOIUGRkZiAhvvvkmmzdvdtudmKFfv3506NCh\nxrTjx4/z8MMPk52dzVlnncWqVatqzBcNXA/IN954Y6Xl119/3SVPmj+1PcgO8Ktf/YqOHTty/Phx\nBz1SqjJ06FCMMbz99ttuuxIzdOrUiaVLl3LyySfXmW/z5s1cfvnltGrVit69e9vii60B+ZZbbqFn\nz561pvfo0aNS9//GG2+sM2gokdGqVasa1w8fPpzHH38cgAcffNBJl5QqVPSQ9Zeic/zHf/wHeXl5\nbNy4sd68q1atYuTIkTz++OO0adMm+s5Ee3A8JSVF1q1bF7xJd+LECSkoKJCpU6fK1KlT5fPPP5cD\nBw5UupG3fv166dSpk95AsvmGRXx8vPj9frn00kuD63Jzc4PPi/fq1cvWGxaxavUd01Dz+XxiWZYM\nGDAg3G30pl6EmlxyySWyevVqSU5ODlunjRs3yrx586LeRmw52caMGRPWa9N1BWNt/NHVpML8fr9s\n27ZNcnJyZO7cueL3+2XXrl0yduxY2+8gx6o1JCBbliV+v18DsoOatG3bVgoLC2XcuHESFxcX1nHP\nz8+XL7/8smkEZGOMjB8/vt5gvHHjRklISNDGb+PJVtUOHTpUSQOfzye//e1vww4Ybu9bU7SGBGSf\nzycbNmyQtm3bakB2UJOrr75ajh07JnfffXdYx/3AgQNy0003NY2AXBGUZ86cKQUFBZUCwMKFC2Xm\nzJly5ZVX1jgxhzb+6J9soda5c2fJysqSZ555RlatWiVDhgwJO1ioJtHXo6pZliVjxoxpiCYakKOk\nyYQJE+TYsWOSk5MjiYmJNR7vPn36yKOPPir333+/tGnTJuptxNb5kCNFdCKbRqGaeIuG6OHz+Ro6\nfYBOLtQIatOkf//+vPTSSyQnJ7NkyRJee+010tLSOP/887n44ovp2rUrW7dupU+fPrWWHUkb0YDc\nDFFNvEW4eqSmppKfn88vfvGLhhSvAbkReLWNaEBuhqgm3kInqPceXm0j0ZhcqAh7PrSYbkOZsYJq\n4i3s0gNUk8biyTYScQ9ZURRFiQ6uvzqtKIqiBNCArCiK4hE0ICuKongEDciKoigeQQOyoiiKR9CA\nrCiK4hE0ICuKongEDciKoigeQQOyoiiKR9CArCiK4hE0ICuKongEDciKoigeQQOyoiiKR4g4IBtj\n5htj7oh2XqXxqCbeQvXwHp7VJIxvT20HjgIlQDHwKTAFiIvwm1ZZwPf15LkWsIDDIZbl9ve43DaX\nNbkC+BY4COwDngOS3D4mMayHAe4B/l2uyUdAX7ePidvmsiYJwFxgN/Aj8DgQH0754faQR4tIewKT\nL98PTAeeDnPbSPlMRBJD7COH6vU6bmnyCXC+iCQDPQl85OAeB+r1Om7pcTnwn8BQoAPwGfCCA/U2\nBdzS5FZgEJAJ9AYGALeHtWWYV5oLq6w7G/CXV7gQuCck7RagkMDV4ToCX2LtVZ62kEDjbUfg6uXn\np55vlxrqvhZY6fbV1mvmpiZV6kwEngfedfuYxKoeBILMqyHLfYFjbh8Tt81lTb4ALg9Z/j/ArnD8\nbtQYsoisBr4ncFUOYowZAfwJuBDoRaB7X9P2pUAOsFt+6vnuNsYMMcYUV8l+pjGmyBizxRhzhzEm\nGp+danY4qUn5uoMEfg6OBR6K9v40dRzU42XgNGNMb2NMPHANsCTqO9QMcDhumSr/dzPGJNfnYyQ3\n9XYT+IkUyjjgWRHZICJHgNyGFCgiK0UkJWTVxwSuZp0INPwrgZsb7XHzxwlNKtYlA92ABwj0RpTq\nOKFHIbCSwLj+UQJDGNMa7XHzxwlNlgB/NMakGWNOBv5Qvr5tfWVFEpC7AgeqrOsC7ApZ3kUEiMg2\nEfmXiPhF5GtgJvDbSMps5tiuSSgi8m8CJ9/L0SqzmeGEHncCZwGnAq2Bu4H/NcbU2/hjFCc0uRf4\nEviKwM3Et4ETwN76NmxUQDbGnEVgx1ZWSSok0Guq4NQ6imnM11WFyj8FlHJc1KQlcFojtmvWOKhH\nf+AVEfleRHwishA4CejTAHdjAqc0EZGjIvJ/RaSriPQE9gNrRcRf37YNCsjGmCRjzCgCPaIXy3ut\nobwKTDTGnFF+ha7r2b29QMe6xlWMMTnGmM7l/2eUl7e4IT43d1zQZLwxpnv5/+kEegPLItqJZoTT\negBrgMuNMZ2NMXHGmKuBeGBrBLvRrHChjXQ1xnQxAQaXl3dXOL6GG5DzjDElBLrytwFzgIlVM4nI\ne8AjQD6BE2JVeVJZDXk3Ay8B24wxxeU7MNQYczgk23BgvTGmFHgXeBP4S5g+N3fc0qQP8Gm5Jp8Q\nGLucFL3darK4pcdsoIDAz+NiAuPHY0Wk6k2mWMQtTU4jMFRRSuA5/VtF5INwHDblj2XYgjHmDOAb\nIEFEfLZVpISNauItVA/v4aYmUZ/LwhgzxhiTYIw5icDVO09PNHdRTbyF6uE9vKKJHZMLTSbwSu13\nBF57nmpDHUrDUE28herhPTyhia1DFoqiKEr46PSbiqIoHiHi15CNMbZ1sUVEnzluBKqJt7BTD6BI\nRNJsLL9Z4tU2oj1kRWna7HDbASV6aEBWFEXxCDpzWgwRHx/PrFmzAGjXrh033HADn3/+OS+//DIv\nvPACR48e5ejRoy57qSixS8RPWTRkLOaxxx4jISGBzp07M3LkSABmzJjBe++9x/r166vl1/HKxlGT\nJqeccgp33XUXkybV/lLdXXfdxT331D3XvGrScGweQ14rIoNsLL9Z4tUx5GhMBC31Wfv27eXRRx8V\ny7LEsizx+/3B/y3LktLSUlm4cGG17SL1LVatJg3uu+8+2bFjh1iWJatXr5ZVq1bJO++8I5s3bw7q\n8PXXX8u8efPq1NLtfWuKFk4bASQhIUFOPvlkmThxYqX2ISKSl5cn/fv3r2m7L9zev6Zo4WoCSHJy\nsvTv31/mzp0rH3zwgZSUlEh6erotbcT2HnJ6ejrLly/n1FNP5d133+XEiRMYYwit98wzz+Tkk0/m\nySef5Oabb+b48eOA9sYaS22adO/enf79+/POO+9gWRYAqamp/OlPf2L69OkA7Nq1ix49etRatmrS\ncMLpjXXv3p2nnnqKX/3qV9XaR8VyYWEh5513Hrt2VZodUnvIjaAhPeSCggIyMzMrabJy5Up+/etf\nc/DgwWr5I2ojdl5p5s+fH+wRP//882FfkYjClSaWrSHH+NJLL63UG9u+fbtq4qAel19+uezdu1d8\nPl/QLMsK/r969WrJy8sLLk+fPl17yDZrEh8fL0OGDJF9+/aJz+eTkpISmTFjhmRmZkpcXJykpaWJ\nz+eTGTNmRL2N2HpTb+zYsRhjWLhwIdOm6UcMvEhaWhr79++nY8eObrsSkyxYsID27dtXBIlqnHHG\nGZXS0tPTnXItZhk5ciSvv/46AEePHmXYsGGsW7cumF5cXMxVV13F22+/Hf3K7bzSHD9+XCzLkuTk\n5OC6lJQUSU1NlY4dO2oP2YWrf4UlJSXJnDlz5J///KcUFRUFe8jFxcWSkJCgmjigR0JCQnCMuOL4\n79mzR7777jvp06ePADJlypRg+tq1ayUtLU17yDZqAgR7xuvXr5crrriiUlpOTo589tln0rdvX1va\niO0nm2VZwXUzZ86UH374Qfx+vxw9elQefvhhDcgOn2wVdvLJJ1caqvjhhx9k7969YlmWvP/++zJo\n0CDVxGY9TjnllGpDFB06dAim9+zZUzZt2iSWZcm//vUvGTx4cE3laECOoiZAMBhXXPwSExMlIyND\nCgsLpaysTHw+n5xzzjlNKyDHx8dXe6pi1apVsmDBAlmwYIEcOHBALMuSzp07a0B28GSrz2bMmCGW\nZcmrr76qmjigR58+fSoF5MmTJ8vChQuDy1u2bKlPMw3IUdYkdDy/pnH9FStW2NaRtHXHysrKxO/3\ny8GDB+Xxxx+vlLZp0ybx+/1y3nnnaUB28GSry8455xzZv3+/BmSH9Xj00UerNf7CwkKZOnWqJCUl\naUB2WJPBgwfLnDlz5JprrpE5c+bImDFjggG5oKBAUlNTbQvItt7U69u3Ly1atODo0aPs3LmzUlqF\nA//+97/tdEFpACNHjiQlJaX+jEpUuffee/mv//qv4HJcXBxLlizhmWeeoays2leEFJtZtWoVq1at\nCi4vXryYuLg4CgsLuffeeykqKrKvcruv/jVZRkaGHDx4sNL4ck3m9lW0qVpDtGjZsqUkJibKrbfe\nKsuXLxfLsmTjxo3SrVs31cQBPfr27Su33HKL+Hw+KS4urtRD7tWrVzgaag85ypqEWmJiovh8Pikt\nLa1tDD+qbcSxHQu1zz//vNoNP238zp9sgDzxxBOVbu5ZliXdu3dXTRzQo2PHjnLkyBGxLEuWLl0q\nAwYMCC77fD656KKLNCA7rElVu++++8Tn88m4cePCblOR+OXo5EIXXHABH330EcYYDh06xC9+8Qsn\nq49ZunTpwtq1a+nUqRMff/wxx44dIyMjg+7duwfzvPXWW2RmZjJ//vxqw0tK9Onbty9r1qxh/fr1\nDB8+nNLSUgDuvPNOZs+e7bJ3CkBhYSFpaWmkpKRw+PDh+jeIAo4F5LZt2/LGG28gIpw4cYJbbrlF\nG75DtG3bluLiYjp16sQFF1xQY55Zs2axb98+CgsLHfYuNpk+fToJCQmVgjHAsGHDiIuLw+/3u+hd\nbJOamsqCBQs46aSTABwLxmDzfMhjxowB4Prrr+fzzz+nQ4cOAMyZM4cnnnjCzqqVEHbs2EFubm6l\nC+CRI0dYsGABO3fu5KabbmLDhg0ajB0iPj6elJQURITS0lLi4+Pp168f/fr1IysrC7/fX/GzWnGB\nK6+8ktGjR9OyZUteeOEFR+u2tYf8/PPPc/ToUVJTUxER/vnPf/L000/zwAMP2FmtUoUTJ05QVFTE\n2LFjmThxIkuXLuXjjz+muLnUtTMAABUJSURBVLiYxMRER3sASuApitatWwOwZMkSEhISGDp0aKU8\nhw8fZv/+/W64F/PceOONwf9/9rOfkZSUxKFDhxyp29aAHBcXF5wjYf369YwaNUofc3OJZcuWAVR6\nJx+c/TmmBGjZsiUbN27kjDPO4MILL6w2u9t1113HihUr2Lp1q4texi49e/YM/t++fXvHgjE4PEF9\nQxGd6rFRqCbeQieo9x5ebSP6TT1FURSPEI0hiyLs+fJtug1lxgqqibewSw9QTRqLJ9tIxEMWiqIo\nSnTQIQtFURSPoAFZURTFI2hAVhRF8QgakBVFUTyCBmRFURSPoAFZURTFI2hAVhRF8QgakBVFUTyC\nBmRFURSPoAFZURTFI2hAVhRF8QgakBVFUTxCxAHZGDPfGHNHtPMqjUc18R6qibfwrB5hfC57O3AU\nKAGKgU+BKUBchJ/hzgK+rydPJvA+ganyIvq8dnMylzW5AvgWOAjsA54Dktw+Jm6bauIta6pxK9we\n8mgRaU9grs/7genA02FuGwkngFeB3ztQV1PDLU0+Ac4XkWSgJ4E5te9xoN6mgGriLZpe3ArzSnNh\nlXVnA34CV4KFwD0habcAhcBu4DpAgF7laQsJnCjtCFy9/MDhcutShw+90B6ypzQp3zYReB541+1j\n4rapJt4yL+jRmLjVqDFkEVkNfA9U+lSuMWYE8CfgwnJnsmrZvhTIAXaLSGK57TbGDDHGFDfGp1jH\nSU3K1x0k8HNwLPBQtPenOaCaeIumELciuam3G+hQZd044FkR2SAiR4DchhQoIitFJCUCn2IdRzQp\nX5cMdAMeINAbUWpGNfEWno5bkQTkrsCBKuu6ALtClnehOImjmojIv4ElwMvRKrMZopp4C0/HrUYF\nZGPMWQR2bGWVpEICV+gKTq2jGP2YXxRxUZOWwGmN2K7Zo5p4i6YQtxoUkI0xScaYUQSuvi+KyNdV\nsrwKTDTGnGGMaQvU9ezeXqCjMSa5jvqMMaY10Kp8ubUxJqEhPjd3XNBkvDGme/n/6cC9wLKIdqKZ\noZp4i6YUt8INyHnGmBICXfnbgDnAxKqZROQ94BEgH9gKrCpPKqsh72bgJWCbMabYGNPFGDPUGHM4\nJFs6gbuaG8qXjxJ43lJxT5M+wKfGmFICj1t9C0yK3m41aVQTb9Hk4pYpfzzDFowxZwDfAAki4rOt\nIiVsVBPvoZp4Czf1iPpcFsaYMcaYBGPMScBsIE9PMndRTbyHauItvKKHHZMLTSbw+uZ3gAVMtaEO\npWGoJt5DNfEWntDD1iELRVEUJXx0+k1FURSPoAFZURTFI7SMtABjjG1jHiJi7Cq7OaOaeAs79QCK\nRCTNxvKbJV5tI9pDVpSmzQ63HVCihwZkRVEUj6ABWVFcZtKkSWzbtg3Lsvjoo4+YNm0aV1xxhdtu\nKW4QhYmgJVx75ZVX5Msvv5QePXqElT9S32LVQo9hVlaW5ObmiohIfn5+2FqpJvboEWpt27aVnTt3\nSllZmfh8PvH5fGJZlvh8Pjly5IgUFBRI796969PkC7f3rylaY8793r17S1FRkeTk5NjWRiK+qdcQ\nRIR+/fqRk5PDvHnznKw6JsnKyuKuu+4iKysruKx4g/bt2zN37ly6du1KUVERW7ZsCaZ17NiR3r17\n07dvX9577z1OO00nbvMC5513HieddBIdO3a0rY6IXwxpyN3KsrIy4uPjueGGG8IKyKJ39BtFhSb5\n+fm1BuGPPvoIgOXLlwfX5ebm1lu2atJwamojgwcPZuXKlfz973/n8ccfZ9WqVcG0bt26cfXVVzNr\n1iwAOnXqxIEDVafwDbJWRAbZ4XdzpqFPWSQlJbF8+XISEhI488wzKSurNu9QkIjaiJNdf7/fL8uX\nL5ekpCT9eezgz7Hc3FzJzc2V/Pz84N+6UE3s1QOQwYMHi2VZdR7rq666SizLkq5du+qQhQOa1GUP\nPfSQWJYlmZmZtsYtR3fM7/fLkiVLws7vtmhN1RqiSU3BWTWxX4/evXvL9u3b5c4776zxOA8cOFBK\nSkrE5/NpQHZIk7qssLDQkYDs2FMWCQk6r7zXyM3NrTakUTGUodjLli1b+O1vf0txcfVvYw4cOJAB\nAwbQpk0bAA4ePOi0e0oIZ599Np07d2bFihVs3rzZ3sqcvNJoD9k7V/+KJy9Cyc3NVU1c0iMhIUFO\nPfVUueqqq4I94wpbvHixDBo0SHvIDmtSYTNnzpSysjK54YYbbI9bjuxYr169pKCgQPx+v1x00UUa\nkD1ystUUlOt7NM7tfWuKVp8OO3fuFMuyxLIsERHZtGmT/PWvfw1aRdojjzyiAdkhTULtu+++k+++\n+86RuOXIjt1www3i9/u1h+zBk60mVBNn9fjHP/4hPp9PDh06JFOnTpUOHTpUSt+1a5f4fD7517/+\npQHZIU2qtpGvvvrKkbjlyHPI8+fP57LLLmP48OGsW7fOiSqVMDHGkJuby7Bhw4LjySKCMfp0m1NM\nnDiRXr16UVZWxldffVUt3e/3u+CVUoHf7+fZZ591pC5HbupZloXf7+fpp5/mjjvq+qCr4ga5ublk\nZ2eTnZ0dvKmXn5/vrlMxxP79+/n8889rDMYpKSl06NABgOeff95p15RyNmzYUH+mKODYiyHvv/8+\nZ511FqecckqdD1WHIvoSQqOoS5OsrKxgT7imF0GysrKCwTg0QFegmjScxk71mJKSwtKlSznzzDPZ\nvn07I0aMYOvWrVWz6YshjaAhmliWRYsWLcIuO5I24uir0+EGYsU+QoNtTdx1111OuhNzTJo0idtv\nv51169YxZsyYSmlt27Zl9uzZXHrppbRq1Yq0tMA0x7169WL79u0ueKtkZmbyyCOPOFafowH5pptu\n0qDsESoCb0UPuOq8FzX1jpXISUxMpGvXrvz4448MHjw4uP4Pf/gDp59+OgMGDEBEKCkp4bPPPiMv\nL0+DsYtcf/31fPbZZ85V6NTdyjfeeEN+97vfhX2nEr2jb4smWVlZUh/5+fmSlZWlmtigR+/evWXf\nvn3VZnersB07dsjbb78t2dnZ4bYTfcoiQk1qs4SEBNm0aZO0b9/esbjl2BhymzZtuPTSS3nllVfC\nLlt0vLJRhKNJXbrX9YSFatJwqupx3XXXMWPGDNLT0zHGMHPmzODbeA899FBDi9cx5EYQThvJzMyk\noKCgQePH0ITGkBXvYIwJ3sD76KOPgrO+6TCF/Tz11FM89dRTbruh1MOMGTMcv6fi6PSbDUV7Y41D\nNfEWNn/kVHvIjcCrbUQ/4aQoiuIRojFkUYQ9X75Nt6HMWEE18RZ26QGqSWPxZBuJeMhCURRFiQ46\nZKEoiuIRNCAriqJ4BA3IiqIoHkEDsqIoikfQgKwoiuIRNCAriqJ4BA3IiqIoHkEDsqIoikfQgKwo\niuIRNCAriqJ4BA3IiqIoHkEDsqIoikeIOCAbY+YbY+6Idl6l8agm3kM18Rae1SOMb09tB44CJUAx\n8CkwBYiL8JtWWcD39eS5BlgLHAK+B/4baOn297jcNjc1Kc83DdhTrsszQILbx8Rtc7mdzAcOh1gZ\nUOL2MYlhPa4FrCqaZIVTfrg95NEi0p7AXJ/3A9OBp8PcNhLaAjcBqcA5wHDg/zlQb1PAFU2MMZcA\ntxLQIh3oCdxtd71NBFc0EZEpIpJYYcBLwGt219sEcCtuAXwWqomIfBTWVmFeaS6ssu5swA9kAguB\ne0LSbgEKgd3AdQS+xNqrPG0hcA/QjsDVy89PV5AuYfjyJyDP7auv2+amJsDfgb+ELA8H9rh9TNw2\nr7ST8m1KgGFuH5NY1YNAD3llY/xu1BiyiKwmMIQwNHS9MWYEgaB5IdCLQPe+pu1LgRxgt/x0Bdlt\njBlijCmuo+oLgA2N8bm546AmfYGCkOUCoLMxpmPUdqaZ4FI7GQv8AHwcnb1oPjisx5nGmCJjzBZj\nzB3GmLC+zhTJTb3dQIcq68YBz4rIBhE5AuQ2pEARWSkiKTWlGWP+ExgE/LURvsYKTmiSCBwMWa74\nv30DfY0VHG0nBO67PC/lXTWlGk7o8TGBXngnAhfIK4GbwykrkoDcFThQZV0XYFfI8i6igDHmMuA+\nIEdEiqJRZjPFCU0OA0khyxX/l0RYbnPFyXbSnUDv7vlolNdMsV0PEdkmIv8SEb+IfA3MBH4bzraN\nCsjGmLMI7NjKKkmFQLeQ5VPrKCasK3j5z4kFBAbov26In7GEg5psAPqFLPcD9orI/nD8jCWcbCfl\nXA18IiLbGrBNzOCCHqHbmHAyNiggG2OSjDGjgJeBF2sIkK8CE40xZxhj2gJ1Pbu3F+hojEmuo75f\nAYuAseXjP0oVnNaEQO/r98aYPsaYFOB2Ajc9lHJc0KSCCagW1XAhbuUYYzqX/59RXt7icHwNNyDn\nGWNKCHTlbwPmABOrZhKR94BHgHxgK7CqPKmshrybCTyes80YU2yM6WKMGWqMORyS7Q4gGXjXGHO4\n3N4L0+fmjiuaiMgSAs+D5wM7CXxK/a5o7lgTxq12gjHmXAK9PH3c7Sfc0mM4sN4YUwq8C7wJ/CUc\nh42dY//GmDOAbwi8OOCzrSIlbFQT76GaeAs39Yj6XBbGmDHGmARjzEnAbALPDetJ5iKqifdQTbyF\nV/SwY3KhycA+4DsCrw9OtaEOpWGoJt5DNfEWntDD1iELRVEUJXx0+k1FURSPoAFZURTFI4T1fnVd\nGGNsG/MQkbAeplYqo5p4Czv1AIpEJM3G8pslXm0j2kNWlKbNDrcdUKKHBmQlyEMPPYTf73fbDUVx\nlZYtW3LqqaeSnZ3Ngw8+yObNm7EsizVr1iAiWJbFE088Qfv20Z9PK+KnLOrq+o8fP77S8nXXXUdW\nVhZz585l7dq1fPjhh+zdu7fWsvXnceNo6M+xX/7yl/zxj39kwoQJxMXFMWHCBBYtWlRjXtWk4dg8\nZLFWRAbZWH6zpC5N8vLyyMnJqW27ijmPmTNnDrfccku1PBG1kShMBC01WefOncWyrDrtnXfeqXHb\nCovUt1i1uo5pVbvmmmtkz549lXQpKyuTe++9VzVxQY9G2Bdu719TtLqOqWVZ4vP5qtnixYtl8+bN\nweUdO3ZEvY3YtmN5eXn1BuRdu3ZpQHb4ZKtqfr+/kh6zZ88Wy7Lkhx9+kJ49e6omDuiRmJgoF110\nkeTm5spnn30mW7duFRGRxYsXy6FDhzQgO6jJqFGjqgXkP//5z3LppZdKixYtJDs7WwYNGiQPPPCA\njBw5sukE5EmTJmlA9tjJFmqpqamyc+dO8fv9snr1ajnnnHMq9RAsy5IbbrhBNbFZD7/fL7t375YP\nPvhA7r//fhk8eHDQhg0bJn6/XwOyQ5r07t1b9u3bJ5ZlyWuvvdaQXylRayMRP/ZWG6+88grz588H\nYOPGjTzzzDP89a/6sQ8v0K1bN6ZOnUrXrl3ZvHkz2dnZlJaWuu1WTDJo0CC2bdtGcXH1LzKNGjWK\nH3/80QWvYpMOHTrQoUPgYyKvvPKKKz7YFpAPHTrEl19+yaJFi3juuec4cOCABmQP0KpVK5588kku\nueQSAPr06eOyR7HNunXrak27++6767zprTQ/bAvIAMOHD+fgwYO1pm/cuNHO6pUaOP/887nkkksQ\nEfbvr/0jHyLC8ePHHfRMCaVfv37069ePG2+80W1XYoZBgwZhjMEYw9y5czn33HOBwOOgFQwYMIB1\n69ZRWFiIz2fDZHB2jo9VWEFBQaWx49LSUomPj7d1LCaWra5j6vf75YcffpD+/fvXmD5r1iwREZkw\nYYJq4oAeNdm1114rfr9fLr300nDy6xhylDRp3769vPbaa7U+ZeHz+SqlWZYlK1asiGobsf3FkPj4\neFq1ahVcPnbsGA8++CAnTpywu2qlCl988QV79uwhJyeHr776qsY8F198MX6/v+KkVRymVatWTJs2\njWXLlpGXl+e2OzFFSUkJ11xzTa3p69atqzbENHDgQK677rroOWH31f/222+v1DtOSEhw5G5lLFtN\nx/Lyyy+XsrIyufPOO2s93rfddpscO3ZMLMuSq6++WjWxUY/abMGCBeL3++W8884LdxvtIUdZk2HD\nhklmZqYkJCTI22+/XWOeAwcOBB8Zffnll6PWRmzdsYyMDNm6dWswGB84cEBatWqlAdnhk+20006T\nTZs2iWVZdQbjo0ePimVZMm/ePElOTlZNbNKjLtu2bZsUFxdL+/btNSC7pElmZqYsXbpUHnvsMSks\nLKwxz44dO4LDF9EMyLbe1Hv33XdJT08PLv/5z3/WG0UukJOTQ+/evWtNz8/P59xzzyU+Ph6AqVP1\n4xVu0aNHD3JycigpKXHblZhl4sSJZGdnk52dXWuetLSfJtjbsmVL1Oq2NSCHBmOAMWPG0LNnz+By\nYmIif/jDH4LL77//Pr/5zW84duyYnW7FLLt37yYjI4Px48fTt29fWrZsyejRo4MTCuXl5TFxYrWP\n8ioOkZ6eztq1a/nggw/cdiWmyc/P5/rrr6dt27YAWJYVTAudy8IYw9KlS7nzzjujV7mdXf/i4uJ6\n39arsOLiYlmxYoUkJibqz+Moa5KRkSH79++v8biLiBw6dEgWL15c6zAFUfo5FqtW3zEFJC4uTl5/\n/XWZP3++tG7dOuwhDnTIwhZNJkyYUO9TFgUFBdKtW7eothFbe8gbNmxg8ODBdebZs2cP99xzD3v2\n7OGtt96y052YZfPmzRQXF5OSklJpvYhw6NAhxo4dy4cffuiSdwrA0KFD+c1vfkNiYqL+QvQAFbHo\nscceo02bNsH1BQUF7N+/nyNHjjBlyhQKCwujW7GdV5oePXpIXl6eHDx4sMbe2ZEjRyQzM1N7Yw5c\n/TMzM2Xv3r1iWZbs2bNHbr31Vpk2bVpDemKqSRT1CDVjjOTn58vOnTsbrAfaQ7ZFkwo75ZRTZNGi\nRcFe8bBhwyQhIUFatGhhSxuxdT7kCkaOHElSUlK19ceOHauzVyw6926j8OrnaWKV+vTo3LkzhYWF\nTJkyhSeffLKhxet8yI3Aq23EkYDcWLTxNw7VxFvUp8eiRYs4ceIE1157bWOK14DcCLzaRjQgN0NU\nE2+hXwzxHl5tI9G4qVeEPR9aTLehzFhBNfEWdukBqklj8WQbibiHrCiKokQH/eq0oiiKR9CArCiK\n4hE0ICuKongEDciKoigeQQOyoiiKR9CArCiK4hE0ICuKongEDciKoigeQQOyoiiKR/j/ZV239Wsf\nBZQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digits(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "p2cHmAH0BkKb",
    "outputId": "d2be9060-2119-4a36-9dae-61e76c23d755"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAH0CAYAAADc9E9DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.countplot(Y_train)\n",
    "ax.set_title('Distribution of Digits', fontsize=14)\n",
    "ax.set_xlabel('Digits', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-q_zEz9TBns1"
   },
   "outputs": [],
   "source": [
    "#Train-Test Split\n",
    "X_dev, X_val, Y_dev, Y_val = train_test_split(X_train, Y_train, test_size=0.03, shuffle=True, random_state=2019)\n",
    "T_dev = pd.get_dummies(Y_dev).values\n",
    "T_val = pd.get_dummies(Y_val).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxeVeQM6BpH_"
   },
   "outputs": [],
   "source": [
    "#Reshape the input \n",
    "X_dev = X_dev.reshape(X_dev.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZevKTtXOeMVT"
   },
   "source": [
    "## CNN Architecture (LeNet-5)\n",
    "\n",
    "Kita akan menggunakan Arsitekture LeNet-5 untuk membuat Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "imTM5jeDBreh",
    "outputId": "3a16bbc9-138e-4631-ca9d-5bf224e579f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "TGPV2V9xBtC1",
    "outputId": "60366cf8-9de0-4f1d-e89f-f9b0ec02129e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 48)        38448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                21588     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "YiZwGVrzB7Jv",
    "outputId": "8810158e-987f-48b1-d92f-c416b7e4a80f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=5e-4)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOFkqjuHB9kr"
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                patience=3, \n",
    "                                verbose=1, \n",
    "                                factor=0.2, \n",
    "                                min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVTIi7SxB_DA"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=10, \n",
    "            width_shift_range=0.1, \n",
    "            height_shift_range=0.1, \n",
    "            zoom_range=0.1)\n",
    "datagen.fit(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtycxzDjfOQY"
   },
   "source": [
    "### Parameters : Epochs 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0us0yHhlfOQa",
    "outputId": "ac321674-ae77-4845-e14a-8da4049cecd4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "408/407 [==============================] - 12s 30ms/step - loss: 0.4707 - acc: 0.8527 - val_loss: 0.1074 - val_acc: 0.9683\n",
      "Epoch 2/50\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.1467 - acc: 0.9551 - val_loss: 0.0681 - val_acc: 0.9786\n",
      "Epoch 3/50\n",
      "408/407 [==============================] - 11s 27ms/step - loss: 0.1053 - acc: 0.9675 - val_loss: 0.0625 - val_acc: 0.9778\n",
      "Epoch 4/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0814 - acc: 0.9750 - val_loss: 0.0451 - val_acc: 0.9881\n",
      "Epoch 5/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0679 - acc: 0.9794 - val_loss: 0.0389 - val_acc: 0.9865\n",
      "Epoch 6/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0587 - acc: 0.9820 - val_loss: 0.0409 - val_acc: 0.9889\n",
      "Epoch 7/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0549 - acc: 0.9830 - val_loss: 0.0381 - val_acc: 0.9897\n",
      "Epoch 8/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0508 - acc: 0.9837 - val_loss: 0.0333 - val_acc: 0.9913\n",
      "Epoch 9/50\n",
      "408/407 [==============================] - 11s 27ms/step - loss: 0.0462 - acc: 0.9853 - val_loss: 0.0284 - val_acc: 0.9937\n",
      "Epoch 10/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0419 - acc: 0.9870 - val_loss: 0.0377 - val_acc: 0.9865\n",
      "Epoch 11/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0401 - acc: 0.9879 - val_loss: 0.0286 - val_acc: 0.9944\n",
      "Epoch 12/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0373 - acc: 0.9878 - val_loss: 0.0210 - val_acc: 0.9952\n",
      "Epoch 13/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0350 - acc: 0.9887 - val_loss: 0.0158 - val_acc: 0.9952\n",
      "Epoch 14/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0320 - acc: 0.9898 - val_loss: 0.0175 - val_acc: 0.9960\n",
      "Epoch 15/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0221 - val_acc: 0.9944\n",
      "Epoch 16/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0207 - val_acc: 0.9952\n",
      "Epoch 17/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0306 - acc: 0.9900 - val_loss: 0.0162 - val_acc: 0.9968\n",
      "Epoch 18/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0267 - acc: 0.9915 - val_loss: 0.0278 - val_acc: 0.9929\n",
      "Epoch 19/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0264 - acc: 0.9915 - val_loss: 0.0258 - val_acc: 0.9944\n",
      "Epoch 20/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0253 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 21/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0179 - acc: 0.9941 - val_loss: 0.0182 - val_acc: 0.9960\n",
      "Epoch 22/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0183 - val_acc: 0.9944\n",
      "Epoch 23/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0168 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 24/50\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0174 - val_acc: 0.9968\n",
      "Epoch 25/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0169 - val_acc: 0.9968\n",
      "Epoch 26/50\n",
      "408/407 [==============================] - 11s 27ms/step - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0184 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 27/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0177 - val_acc: 0.9952\n",
      "Epoch 28/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.0176 - val_acc: 0.9952\n",
      "Epoch 29/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0172 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 30/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0122 - acc: 0.9962 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 31/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 32/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0172 - val_acc: 0.9952\n",
      "Epoch 33/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0172 - val_acc: 0.9952\n",
      "Epoch 34/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 35/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0121 - acc: 0.9960 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 36/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0170 - val_acc: 0.9960\n",
      "Epoch 37/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0170 - val_acc: 0.9952\n",
      "Epoch 38/50\n",
      "408/407 [==============================] - 11s 27ms/step - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0170 - val_acc: 0.9952\n",
      "Epoch 39/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0170 - val_acc: 0.9952\n",
      "Epoch 40/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 41/50\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0119 - acc: 0.9959 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 42/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 43/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0125 - acc: 0.9965 - val_loss: 0.0170 - val_acc: 0.9960\n",
      "Epoch 44/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0115 - acc: 0.9968 - val_loss: 0.0171 - val_acc: 0.9960\n",
      "Epoch 45/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0170 - val_acc: 0.9960\n",
      "Epoch 46/50\n",
      "408/407 [==============================] - 10s 26ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0171 - val_acc: 0.9960\n",
      "Epoch 47/50\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0171 - val_acc: 0.9960\n",
      "Epoch 48/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0170 - val_acc: 0.9960\n",
      "Epoch 49/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0171 - val_acc: 0.9960\n",
      "Epoch 50/50\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0171 - val_acc: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cc81cf5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_dev, T_dev, batch_size=100), steps_per_epoch=len(X_dev)/100, \n",
    "                    epochs=50, validation_data=(X_val, T_val), callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2VWnmtXCfOQd",
    "outputId": "b7d27d4d-045d-418f-d826-a5d6849c4ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260/1260 [==============================] - 0s 88us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val, T_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UNMaJmNYfOQf",
    "outputId": "2996d3aa-f06f-4596-d626-28c4722f3214"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017105051358036385, 0.9960317462209671]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvVbytcGfOQh"
   },
   "source": [
    "#### Prediksi Data Test (Epoch 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIiExFpMfOQi"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Tugas 2 Deep Learning/LeNet/test.csv')\n",
    "X_test = np.array(df_test)\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBTWkJ5ifOQk"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "Y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Jir2hNHfOQm",
    "outputId": "e48591c2-1e80-41bc-b536-114bd08e2bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, 0, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "Y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jw0U678kfOQo"
   },
   "source": [
    "#### Membuat Hasil Predisksi (Epoch 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "NlWalM0vfOQp",
    "outputId": "5eea6cda-6ad8-4e6f-e7aa-5cc79675ac63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Tugas 2 Deep Learning/LeNet/sample_submission.csv')\n",
    "df_out['Label'] = Y_test\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQ7JnUpQfOQq"
   },
   "outputs": [],
   "source": [
    "df_out.to_csv('out 50 epoch.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PCgWmoHeglM"
   },
   "source": [
    "### Parameters : Epochs 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dwXaiXYGCBJS",
    "outputId": "40858105-18ae-4e05-88bb-98324f08767c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "408/407 [==============================] - 26s 63ms/step - loss: 0.4731 - acc: 0.8517 - val_loss: 0.1011 - val_acc: 0.9722\n",
      "Epoch 2/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.1419 - acc: 0.9573 - val_loss: 0.0833 - val_acc: 0.9746\n",
      "Epoch 3/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.1037 - acc: 0.9681 - val_loss: 0.0585 - val_acc: 0.9817\n",
      "Epoch 4/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0802 - acc: 0.9755 - val_loss: 0.0497 - val_acc: 0.9881\n",
      "Epoch 5/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0697 - acc: 0.9782 - val_loss: 0.0535 - val_acc: 0.9841\n",
      "Epoch 6/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0590 - acc: 0.9820 - val_loss: 0.0480 - val_acc: 0.9865\n",
      "Epoch 7/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0575 - acc: 0.9816 - val_loss: 0.0382 - val_acc: 0.9889\n",
      "Epoch 8/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0495 - acc: 0.9844 - val_loss: 0.0374 - val_acc: 0.9881\n",
      "Epoch 9/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0470 - acc: 0.9853 - val_loss: 0.0448 - val_acc: 0.9889\n",
      "Epoch 10/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0415 - acc: 0.9876 - val_loss: 0.0445 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0303 - acc: 0.9908 - val_loss: 0.0239 - val_acc: 0.9944\n",
      "Epoch 12/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0284 - acc: 0.9912 - val_loss: 0.0214 - val_acc: 0.9944\n",
      "Epoch 13/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0265 - acc: 0.9917 - val_loss: 0.0206 - val_acc: 0.9968\n",
      "Epoch 14/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0253 - acc: 0.9922 - val_loss: 0.0254 - val_acc: 0.9944\n",
      "Epoch 15/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0197 - val_acc: 0.9960\n",
      "Epoch 16/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0217 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 17/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0214 - acc: 0.9931 - val_loss: 0.0205 - val_acc: 0.9968\n",
      "Epoch 18/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0218 - acc: 0.9936 - val_loss: 0.0210 - val_acc: 0.9960\n",
      "Epoch 19/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0214 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 20/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.0209 - val_acc: 0.9944\n",
      "Epoch 21/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0205 - val_acc: 0.9960\n",
      "Epoch 22/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0202 - acc: 0.9938 - val_loss: 0.0209 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 23/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0207 - val_acc: 0.9944\n",
      "Epoch 24/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.0206 - val_acc: 0.9952\n",
      "Epoch 25/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0186 - acc: 0.9939 - val_loss: 0.0206 - val_acc: 0.9952\n",
      "Epoch 26/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0204 - val_acc: 0.9944\n",
      "Epoch 27/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0203 - val_acc: 0.9944\n",
      "Epoch 28/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0203 - val_acc: 0.9952\n",
      "Epoch 29/100\n",
      "408/407 [==============================] - 10s 23ms/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 30/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 31/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0189 - acc: 0.9942 - val_loss: 0.0203 - val_acc: 0.9960\n",
      "Epoch 32/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0195 - acc: 0.9944 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 33/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 34/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.0202 - val_acc: 0.9960\n",
      "Epoch 35/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0201 - val_acc: 0.9960\n",
      "Epoch 36/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0188 - acc: 0.9944 - val_loss: 0.0201 - val_acc: 0.9960\n",
      "Epoch 37/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0201 - val_acc: 0.9960\n",
      "Epoch 38/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0201 - val_acc: 0.9960\n",
      "Epoch 39/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0198 - acc: 0.9936 - val_loss: 0.0200 - val_acc: 0.9960\n",
      "Epoch 40/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 41/100\n",
      "408/407 [==============================] - 10s 23ms/step - loss: 0.0188 - acc: 0.9940 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 42/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 43/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 44/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 45/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 46/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0199 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 47/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 48/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0189 - acc: 0.9943 - val_loss: 0.0204 - val_acc: 0.9968\n",
      "Epoch 49/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0189 - acc: 0.9943 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 50/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0201 - acc: 0.9938 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 51/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0204 - acc: 0.9939 - val_loss: 0.0202 - val_acc: 0.9960\n",
      "Epoch 52/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 53/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 54/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 55/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 56/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 57/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 58/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 59/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0200 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 60/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 61/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0196 - acc: 0.9942 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 62/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 63/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 64/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0201 - acc: 0.9944 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 65/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 66/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 67/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0192 - acc: 0.9943 - val_loss: 0.0199 - val_acc: 0.9968\n",
      "Epoch 68/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0199 - val_acc: 0.9968\n",
      "Epoch 69/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0199 - val_acc: 0.9968\n",
      "Epoch 70/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 71/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0190 - acc: 0.9941 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 72/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0190 - acc: 0.9941 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 73/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 74/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 75/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 76/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 77/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0188 - acc: 0.9942 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 78/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 79/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 80/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0183 - acc: 0.9947 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 81/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0200 - val_acc: 0.9968\n",
      "Epoch 82/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0179 - acc: 0.9945 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 83/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0188 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 84/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 85/100\n",
      "408/407 [==============================] - 11s 26ms/step - loss: 0.0183 - acc: 0.9939 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 86/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0183 - acc: 0.9941 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 87/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 88/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0186 - acc: 0.9943 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 89/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 90/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 91/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0191 - acc: 0.9944 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 92/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0175 - acc: 0.9950 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 93/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0187 - acc: 0.9938 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 94/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0198 - acc: 0.9935 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 95/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0203 - val_acc: 0.9968\n",
      "Epoch 96/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0204 - val_acc: 0.9968\n",
      "Epoch 97/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 98/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0187 - acc: 0.9938 - val_loss: 0.0201 - val_acc: 0.9968\n",
      "Epoch 99/100\n",
      "408/407 [==============================] - 10s 25ms/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0202 - val_acc: 0.9968\n",
      "Epoch 100/100\n",
      "408/407 [==============================] - 10s 24ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0201 - val_acc: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31ee01ed30>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_dev, T_dev, batch_size=100), steps_per_epoch=len(X_dev)/100, \n",
    "                    epochs=100, validation_data=(X_val, T_val), callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b_9pX2gKCDM_",
    "outputId": "041fddda-9a65-49ed-dbd8-c4c2d0427c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260/1260 [==============================] - 0s 110us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val, T_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3RJAPSUTCEWA",
    "outputId": "ba6c1059-d545-4e81-b566-14b88f152b8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.020082404397221074, 0.9968253970146179]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4CJqa7cqetR_"
   },
   "source": [
    "#### Prediksi Data (Epoch 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBMKLsrCCF71"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Tugas 2 Deep Learning/Dataset/test.csv')\n",
    "X_test = np.array(df_test)\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIQVcgyICHKw"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "Y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tWOxBBYWCIbw",
    "outputId": "603a3586-cff3-451d-cae8-0cc4509e9566"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, 0, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "Y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HWIGah4ezUe"
   },
   "source": [
    "#### Membuat Hasil Predisksi (Epoch 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PTwktLHGCKY1",
    "outputId": "ed2b8634-4e91-4574-bf38-8ce2ee822a83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Tugas 2 Deep Learning/Dataset/sample_submission.csv')\n",
    "df_out['Label'] = Y_test\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOXb_KGiCMUo"
   },
   "outputs": [],
   "source": [
    "df_out.to_csv('LeNet output Epoch 100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARxu6sBwfJ10"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST CNN With LeNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
